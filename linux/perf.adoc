:toc:

// 保证所有的目录层级都可以正常显示图片
:path: linux/
:imagesdir: ../image/

// 只有book调用的时候才会走到这里
ifdef::rootpath[]
:imagesdir: {rootpath}{path}{imagesdir}
endif::rootpath[]

== perf

- trace system calls faster than trace
- profile your C, Go, C++, node.js, Rust, and Java/JVM programs really easily
- trace or count almost `any` kernel event

The perf system is split into 2 parts:

- a program in userspace called perf
- a system in the Linux kernel

When you run perf record, perf stat, or perf top to get information about a program, here's what happens:

- perf asks the kernel to collect information.

image::../image/linux/image-2025-02-19-17-11-02-786.png[]

- the kernel gets samples/traces/CPU counters from the programs perf asks about.
- perf displays the data back to you in a (hopefully) useful way.

=== Command

==== List Events

[source,bash]
----
# List all events
perf list
# List all tracepoints
perf list tracepoint
# List all kprobes
perf list kprobe
# List all uprobes
perf list uprobe
# List all perf events
perf list perf_event
# List all breakpoints
perf list breakpoint
----


==== Counting Events

[source,bash]
----
# CPU counter statistics for the specified command:
perf stat command

# Detailed CPU counter statistics (includes extras) for the specified command:
perf stat -d command

# CPU counter statistics for the specified PID, until Ctrl-C:
perf stat -p PID

# CPU counter statistics for the entire system, for 5 seconds:
perf stat -a sleep 5

# Various basic CPU statistics, system wide, for 10 seconds:
perf stat -e cycles,instructions,cache-references,cache-misses,bus-cycles -a sleep 10

# Various CPU level 1 data cache statistics for the specified command:
perf stat -e L1-dcache-loads,L1-dcache-load-misses,L1-dcache-stores command

# Various CPU data TLB statistics for the specified command:
perf stat -e dTLB-loads,dTLB-load-misses,dTLB-prefetch-misses command

# Various CPU last level cache statistics for the specified command:
perf stat -e LLC-loads,LLC-load-misses,LLC-stores,LLC-prefetches command

# Using raw PMC counters, eg, counting unhalted core cycles:
perf stat -e r003c -a sleep 5

# PMCs: counting cycles and frontend stalls via raw specification:
perf stat -e cycles -e cpu/event=0x0e,umask=0x01,inv,cmask=0x01/ -a sleep 5

# Count syscalls per-second system-wide:
perf stat -e raw_syscalls:sys_enter -I 1000 -a

# Count system calls by type for the specified PID, until Ctrl-C:
perf stat -e 'syscalls:sys_enter_*' -p PID

# Count system calls by type for the entire system, for 5 seconds:
perf stat -e 'syscalls:sys_enter_*' -a sleep 5

# Count scheduler events for the specified PID, until Ctrl-C:
perf stat -e 'sched:*' -p PID

# Count scheduler events for the specified PID, for 10 seconds:
perf stat -e 'sched:*' -p PID sleep 10

# Count ext4 events for the entire system, for 10 seconds:
perf stat -e 'ext4:*' -a sleep 10

# Count block device I/O events for the entire system, for 10 seconds:
perf stat -e 'block:*' -a sleep 10

# Count all vmscan events, printing a report every second:
perf stat -e 'vmscan:*' -a -I 1000
----

==== Profiling

[source,bash]
----
# Sample on-CPU functions for the specified command, at 99 Hertz:
perf record -F 99 command

# Sample on-CPU functions for the specified PID, at 99 Hertz, until Ctrl-C:
perf record -F 99 -p PID

# Sample on-CPU functions for the specified PID, at 99 Hertz, for 10 seconds:
perf record -F 99 -p PID sleep 10

# Sample CPU stack traces (via frame pointers) for the specified PID, at 99 Hertz, for 10 seconds:
perf record -F 99 -p PID -g -- sleep 10

# Sample CPU stack traces for the PID, using dwarf (dbg info) to unwind stacks, at 99 Hertz, for 10 seconds:
perf record -F 99 -p PID --call-graph dwarf sleep 10

# Sample CPU stack traces for the entire system, at 99 Hertz, for 10 seconds (< Linux 4.11):
perf record -F 99 -ag -- sleep 10

# Sample CPU stack traces for the entire system, at 99 Hertz, for 10 seconds (>= Linux 4.11):
perf record -F 99 -g -- sleep 10

# If the previous command didn't work, try forcing perf to use the cpu-clock event:
perf record -F 99 -e cpu-clock -ag -- sleep 10

# Sample CPU stack traces for a container identified by its /sys/fs/cgroup/perf_event cgroup:
perf record -F 99 -e cpu-clock --cgroup=docker/1d567f4393190204...etc... -a -- sleep 10

# Sample CPU stack traces for the entire system, with dwarf stacks, at 99 Hertz, for 10 seconds:
perf record -F 99 -a --call-graph dwarf sleep 10

# Sample CPU stack traces for the entire system, using last branch record for stacks, ... (>= Linux 4.?):
perf record -F 99 -a --call-graph lbr sleep 10

# Sample CPU stack traces, once every 10,000 Level 1 data cache misses, for 5 seconds:
perf record -e L1-dcache-load-misses -c 10000 -ag -- sleep 5

# Sample CPU stack traces, once every 100 last level cache misses, for 5 seconds:
perf record -e LLC-load-misses -c 100 -ag -- sleep 5

# Sample on-CPU kernel instructions, for 5 seconds:
perf record -e cycles:k -a -- sleep 5

# Sample on-CPU user instructions, for 5 seconds:
perf record -e cycles:u -a -- sleep 5

# Sample on-CPU user instructions precisely (using PEBS), for 5 seconds:
perf record -e cycles:up -a -- sleep 5

# Perform branch tracing (needs HW support), for 1 second:
perf record -b -a sleep 1

# Sample CPUs at 49 Hertz, and show top addresses and symbols, live (no perf.data file):
perf top -F 49

# Sample CPUs at 49 Hertz, and show top process names and segments, live:
perf top -F 49 -ns comm,dso
----


==== Static Tracing

[source,bash]
----
# Trace new processes, until Ctrl-C:
perf record -e sched:sched_process_exec -a

# Sample (take a subset of) context-switches, until Ctrl-C:
perf record -e context-switches -a

# Trace all context-switches, until Ctrl-C:
perf record -e context-switches -c 1 -a

# Include raw settings used (see: man perf_event_open):
perf record -vv -e context-switches -a

# Trace all context-switches via sched tracepoint, until Ctrl-C:
perf record -e sched:sched_switch -a

# Sample context-switches with stack traces, until Ctrl-C:
perf record -e context-switches -ag

# Sample context-switches with stack traces, for 10 seconds:
perf record -e context-switches -ag -- sleep 10

# Sample CS, stack traces, and with timestamps (< Linux 3.17, -T now default):
perf record -e context-switches -ag -T

# Sample CPU migrations, for 10 seconds:
perf record -e migrations -a -- sleep 10

# Trace all connect()s with stack traces (outbound connections), until Ctrl-C:
perf record -e syscalls:sys_enter_connect -ag

# Trace all accepts()s with stack traces (inbound connections), until Ctrl-C:
perf record -e syscalls:sys_enter_accept* -ag

# Trace all block device (disk I/O) requests with stack traces, until Ctrl-C:
perf record -e block:block_rq_insert -ag

# Sample at most 100 block device requests per second, until Ctrl-C:
perf record -F 100 -e block:block_rq_insert -a

# Trace all block device issues and completions (has timestamps), until Ctrl-C:
perf record -e block:block_rq_issue -e block:block_rq_complete -a

# Trace all block completions, of size at least 100 Kbytes, until Ctrl-C:
perf record -e block:block_rq_complete --filter 'nr_sector > 200'

# Trace all block completions, synchronous writes only, until Ctrl-C:
perf record -e block:block_rq_complete --filter 'rwbs == "WS"'

# Trace all block completions, all types of writes, until Ctrl-C:
perf record -e block:block_rq_complete --filter 'rwbs ~ "*W*"'

# Sample minor faults (RSS growth) with stack traces, until Ctrl-C:
perf record -e minor-faults -ag

# Trace all minor faults with stack traces, until Ctrl-C:
perf record -e minor-faults -c 1 -ag

# Sample page faults with stack traces, until Ctrl-C:
perf record -e page-faults -ag

# Trace all ext4 calls, and write to a non-ext4 location, until Ctrl-C:
perf record -e 'ext4:*' -o /tmp/perf.data -a

# Trace kswapd wakeup events, until Ctrl-C:
perf record -e vmscan:mm_vmscan_wakeup_kswapd -ag

# Add Node.js USDT probes (Linux 4.10+):
perf buildid-cache --add `which node`

# Trace the node http__server__request USDT event (Linux 4.10+):
perf record -e sdt_node:http__server__request -a
----

==== Dynamic Tracing

[source,bash]
----
# Add a tracepoint for the kernel tcp_sendmsg() function entry ("--add" is optional):
perf probe --add tcp_sendmsg

# Remove the tcp_sendmsg() tracepoint (or use "--del"):
perf probe -d tcp_sendmsg

# Add a tracepoint for the kernel tcp_sendmsg() function return:
perf probe 'tcp_sendmsg%return'

# Show available variables for the kernel tcp_sendmsg() function (needs debuginfo):
perf probe -V tcp_sendmsg

# Show available variables for the kernel tcp_sendmsg() function, plus external vars (needs debuginfo):
perf probe -V tcp_sendmsg --externs

# Show available line probes for tcp_sendmsg() (needs debuginfo):
perf probe -L tcp_sendmsg

# Show available variables for tcp_sendmsg() at line number 81 (needs debuginfo):
perf probe -V tcp_sendmsg:81

# Add a tracepoint for tcp_sendmsg(), with three entry argument registers (platform specific):
perf probe 'tcp_sendmsg %ax %dx %cx'

# Add a tracepoint for tcp_sendmsg(), with an alias ("bytes") for the %cx register (platform specific):
perf probe 'tcp_sendmsg bytes=%cx'

# Trace previously created probe when the bytes (alias) variable is greater than 100:
perf record -e probe:tcp_sendmsg --filter 'bytes > 100'

# Add a tracepoint for tcp_sendmsg() return, and capture the return value:
perf probe 'tcp_sendmsg%return $retval'

# Add a tracepoint for tcp_sendmsg(), and "size" entry argument (reliable, but needs debuginfo):
perf probe 'tcp_sendmsg size'

# Add a tracepoint for tcp_sendmsg(), with size and socket state (needs debuginfo):
perf probe 'tcp_sendmsg size sk->__sk_common.skc_state'

# Tell me how on Earth you would do this, but don't actually do it (needs debuginfo):
perf probe -nv 'tcp_sendmsg size sk->__sk_common.skc_state'

# Trace previous probe when size is non-zero, and state is not TCP_ESTABLISHED(1) (needs debuginfo):
perf record -e probe:tcp_sendmsg --filter 'size > 0 && skc_state != 1' -a

# Add a tracepoint for tcp_sendmsg() line 81 with local variable seglen (needs debuginfo):
perf probe 'tcp_sendmsg:81 seglen'

# Add a tracepoint for do_sys_open() with the filename as a string (needs debuginfo):
perf probe 'do_sys_open filename:string'

# Add a tracepoint for myfunc() return, and include the retval as a string:
perf probe 'myfunc%return +0($retval):string'

# Add a tracepoint for the user-level malloc() function from libc:
perf probe -x /lib64/libc.so.6 malloc

# Add a tracepoint for this user-level static probe (USDT, aka SDT event):
perf probe -x /usr/lib64/libpthread-2.24.so %sdt_libpthread:mutex_entry

# List currently available dynamic probes:
perf probe -l
----


==== Mixed

[source,bash]
----
# Trace system calls by process, showing a summary refreshing every 2 seconds:
perf top -e raw_syscalls:sys_enter -ns comm

# Trace sent network packets by on-CPU process, rolling output (no clear):
stdbuf -oL perf top -e net:net_dev_xmit -ns comm | strings

# Sample stacks at 99 Hertz, and, context switches:
perf record -F99 -e cpu-clock -e cs -a -g

# Sample stacks to 2 levels deep, and, context switch stacks to 5 levels (needs 4.8):
perf record -F99 -e cpu-clock/max-stack=2/ -e cs/max-stack=5/ -a -g
----

==== Special

[source,bash]
----
# Record cacheline events (Linux 4.10+):
perf c2c record -a -- sleep 10

# Report cacheline events from previous recording (Linux 4.10+):
perf c2c report
----

==== Reporting

[source,bash]
----
# Show perf.data in an ncurses browser (TUI) if possible:
perf report

# Show perf.data with a column for sample count:
perf report -n

# Show perf.data as a text report, with data coalesced and percentages:
perf report --stdio

# Report, with stacks in folded format: one line per stack (needs 4.4):
perf report --stdio -n -g folded

# List all events from perf.data:
perf script

# List all perf.data events, with data header (newer kernels; was previously default):
perf script --header

# List all perf.data events, with customized fields (< Linux 4.1):
perf script -f time,event,trace

# List all perf.data events, with customized fields (>= Linux 4.1):
perf script -F time,event,trace

# List all perf.data events, with my recommended fields (needs record -a; newer kernels):
perf script --header -F comm,pid,tid,cpu,time,event,ip,sym,dso

# List all perf.data events, with my recommended fields (needs record -a; older kernels):
perf script -f comm,pid,tid,cpu,time,event,ip,sym,dso

# Dump raw contents from perf.data as hex (for debugging):
perf script -D

# Disassemble and annotate instructions with percentages (needs some debuginfo):
perf annotate --stdio
----


=== 参数

- `-F`: pic sample frequency
- `-g`: record stack traces
- `-p`: trace process
- `-e`: choose events to record
- `-a`: trace all processes
- `-i`: input file
- `-p`: specify a PID

[source,bash]
----
# Sample CPUs at 49 Hertz, show top symbols:
perf top -F 49
# Sample CPUs, show top process names and segments:
perf top -ns comm,dso
# Count system calls by process, refreshing every 1 second:
perf top -e raw_syscalls:sys_enter -ns comm -d 1
# Count sent network packets by process, rolling output:
stdbuf -oL perf top -e net:net_dev_xmit -ns comm | strings

# *perf stat counteventsFCPUcounters9*
# CPU counter statistics for COMMAND:
perf stat COMMAND
# *Detailed* CPU counter statistics for COMMAND:
perf stat -ddd command
# Count system calls for PID, until Ctrl-C:
perf stat -e 'syscalls:sys_enter_*' -p PID
# Count block device I/O events for the entire system, for 10
seconds:
perf stat -e 'block:*' -a sleep 10


# *Reporting*
# Show perf.data in an ncurses browser:
perf report
# Show perf.data as a text report:
perf report --stdio
# List all events from perf.data:
perf script
# Annotate assembly instructions from perf.data
# with percentages
perf annotate [--stdio]

# *perf trace trace system calls otherevents*
# Trace syscalls system wide
perf trace
# Trace syscalls for PID
perf trace -p PID

# *perf record record profiling data*
# Sample CPU functions for COMMAND at 99 Hertz:
perf record -F 99 COMMAND
# Sample CPU functions for PID, until Ctrl-C:
perf record -p PID
# Sample CPU functions for PID, for 10 seconds:
perf record -p PID sleep 10
# Sample CPU stack traces for PID, for 10 seconds:
perf record -p PID -g -- sleep 10
# Sample CPU stack traces for PID, using DWARF to unwind stack:
perf record -p PID --call-graph dwarf

# *perfrecord record tracing data*
# Trace new processes, until Ctrl-C:
perf record -e sched:sched_process_exec -a
# Trace all context switches, until Ctrl-C:
perf record -e context-switches -a
# Trace all context switches with stack traces, for 10 seconds: 上下文切换是指从一个进程或线程切换到另一个的过程，特别是针对高性能的应用，非常有用
perf record -e context-switches -ag -- sleep 10
# Trace all page faults with stack traces, until Ctrl-C: 缓存未命中，对文件经常读写时会用到
perf record -e page-faults -ag

# *adding new trace events*
# Add a tracepoint for kernel function tcp_sendmsg():
perf probe 'tcp_sendmsg'
# Trace previously created probe:
perf record -e probe:tcp_sendmsg -a
# Add a tracepoint for myfunc() and include the retval as a string:
perf probe 'myfunc%return +0($retval):string'
# Trace previous probe when size > 0:
perf record -e probe:tcp_sendmsg --filter 'size > 0' -a
# Add a tracepoint for do_sys_open() with the filename as a string:
perf probe 'do_sys_open filename:string'
----

=== pef top

使用top命令，你能看出进程占用的CPU百分比，使用perf top你能看出函数占用cpu的情况。

如果你想知道具体哪个函数占用CPU，使用 `perf top` 命令来查看。

[source,bash]
----
# perf top
Samples: 36K of event 'cycles:P', 4000 Hz, Event count (approx.): 12219433698 lost: 0/0 drop: 0/0
Overhead  Shared Object                          Symbol
   1.93%  perf                                   [.] __symbols__insert
   1.72%  perf                                   [.] rb_next
   1.48%  [kernel]                               [k] __update_blocked_fair
   0.94%  perf                                   [.] kallsyms__parse
   0.86%  [kernel]                               [k] module_get_kallsym
   0.67%  [kernel]                               [k] kallsyms_expand_symbol.constprop.0
   0.61%  [kernel]                               [k] memcpy_erms
   0.61%  [kernel]                               [k] vsnprintf
   ...
----

以第一行为例：

- 1.93% : CPU使用百分比
- [./k] : 用户态/内核态
- __symbols__insert ： 符号或函数名


=== perf record

和top命令一样，perf record命令只是能让你有个对整体状况有个了解，想要深入挖掘，需要使用perf report命令。

perf record和perf top收集的信息一样，但是perf record会将收集的信息perf.data保存在当前目录，后面有需要的时候可以进行分析。

- perf record [COMMAND] : 运行命令，知道命令退出
- perf record PID : 监控指定进程，知道CTRL+C退出
- perf record -a : 监控所有进程，知道CTRL+C退出

当然perf也能够支持定时任务，比如：

[source,bash]
----
# 监控 pid 为 8325 的进程，5秒后退出
perf record -p 8325 sleep 5
----

如果你不是很确定是那个函数导致的问题，可以使用 `-e` 参数指定事件，然后使用模糊匹配来监控所有相关的函数

[source,bash]
----
# 监控网络相关的函数
sudo perf record -e 'net:*' -ag -- sleep 60
# 监控系统调用相关函数， -g表示收集函数调用栈
perf record -e syscalls:sys_enter_connect -ag
----

如果只是从函数还是不能断定到底哪里出现了问题，可以在perf record之后，使用perf annotate命令来具体看下哪条指令占用的时间比较久，perf annotate会自动将对应函数进行反汇编。

[source,bash]
----
# 默认会使用当前目录下的perf.data文件
perf annotate
# 也可以使用-i 指定perf.data文件
perf annotate -i perf.data
----

如果你嫌弃perf.data可读性差，可以使用 perf script命令将perf.data转化为可读性高的文本。

[source,bash]
----
perf script > performance.txt
----

当然了一图胜千言，如果你想以图形的方式来查看，可以使用Flamegraph，地址为：`github.com/brendangregg/Flamegraph`

[source,bash]
----
sudo perf script | stackcollapse-perf.pl | flamegraph.pl > graph.svg
----

=== perf stat CPU counters

If you're writing high-performance programs, there  are a lot of CPU/hardware-level events you might be interested in counting:

- L1 cache hits/misses
- instructions per cycle
- page faults
- branch prediction misses
- CPU  cycles
- TLB misses

最后，千万不要忘记man手册

[source,bash]
----
# man 中对perf的子命令也进行了收录
man perf stat
man perf record
man perf report
man perf trace
man perf top
----
































